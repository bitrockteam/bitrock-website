(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{224:function(a,t,e){"use strict";e.r(t);var i=e(6),r=Object(i.a)({},function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("p",[a._v("In this "),e("strong",[a._v("three-day hands-on course")]),a._v(" you will learn how to build an application that can publish data to, and subscribe to data from, an "),e("strong",[a._v("Apache Kafka cluster")]),a._v(". ")]),a._v(" "),e("p",[e("img",{attrs:{src:"/img/confluent_logo.png",alt:"/img/confluent_logo.png"}})]),a._v(" "),e("p",[a._v("You will learn the role of Kafka in the modern data distribution pipeline, discuss core Kafka architectural concepts and components, and review the "),e("strong",[a._v("Kafka")]),a._v(" developer "),e("strong",[a._v("APIs")]),a._v(". As well as core "),e("strong",[a._v("Kafka")]),a._v(", "),e("strong",[a._v("Kafka Connect")]),a._v(", and "),e("strong",[a._v("Kafka Streams")]),a._v(", the course also covers other components in the broader "),e("strong",[a._v("Confluent Platform")]),a._v(", such as the "),e("strong",[a._v("Schema Registry")]),a._v(" and the "),e("strong",[a._v("REST Proxy")]),a._v(".")]),a._v(" "),e("h3",{attrs:{id:"hands-on-training"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hands-on-training","aria-hidden":"true"}},[a._v("#")]),a._v(" Hands-On Training")]),a._v(" "),e("p",[a._v("Throughout the course, hands-on exercises reinforce the topics being discussed. Exercises include:")]),a._v(" "),e("ul",[e("li",[a._v("Using Kafka’s command-line tools")]),a._v(" "),e("li",[a._v("Writing Consumers and Producers")]),a._v(" "),e("li",[a._v("Writing a multi-threaded Consumer")]),a._v(" "),e("li",[a._v("Using the REST Proxy")]),a._v(" "),e("li",[a._v("Storing Avro data in Kafka with the Schema Registry")]),a._v(" "),e("li",[a._v("Ingesting data with Kafka Connect")])]),a._v(" "),e("h3",{attrs:{id:"who-should-attend"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#who-should-attend","aria-hidden":"true"}},[a._v("#")]),a._v(" Who Should Attend?")]),a._v(" "),e("p",[a._v("This course is designed for application developers, ETL (extract, transform, and load) developers, and data scientists who need to interact with Kafka clusters as a source of, or destination for, data.")]),a._v(" "),e("h3",{attrs:{id:"course-prerequisites"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#course-prerequisites","aria-hidden":"true"}},[a._v("#")]),a._v(" Course Prerequisites")]),a._v(" "),e("p",[a._v("Attendees should be familiar with developing in Java (preferred)\nor Python. No prior knowledge of Kafka is required.")]),a._v(" "),e("hr"),a._v(" "),e("h1",{attrs:{id:"course-contents"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#course-contents","aria-hidden":"true"}},[a._v("#")]),a._v(" COURSE CONTENTS")]),a._v(" "),e("h3",{attrs:{id:"the-motivation-for-apache-kafka"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#the-motivation-for-apache-kafka","aria-hidden":"true"}},[a._v("#")]),a._v(" The Motivation for Apache Kafka")]),a._v(" "),e("ul",[e("li",[a._v("Systems Complexity")]),a._v(" "),e("li",[a._v("Real-Time Processing is Becoming Prevalent")]),a._v(" "),e("li",[a._v("Kafka: A Stream Data Platform")])]),a._v(" "),e("h3",{attrs:{id:"kafka-fundamentals"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#kafka-fundamentals","aria-hidden":"true"}},[a._v("#")]),a._v(" Kafka Fundamentals")]),a._v(" "),e("ul",[e("li",[a._v("An Overview of Kafka")]),a._v(" "),e("li",[a._v("Kafka Producers")]),a._v(" "),e("li",[a._v("Kafka Brokers")]),a._v(" "),e("li",[a._v("Kafka Consumers")]),a._v(" "),e("li",[a._v("Kafka’s Use of ZooKeeper")]),a._v(" "),e("li",[a._v("Kafka Efficiency")])]),a._v(" "),e("h3",{attrs:{id:"kafka’s-architecture"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#kafka’s-architecture","aria-hidden":"true"}},[a._v("#")]),a._v(" Kafka’s Architecture")]),a._v(" "),e("ul",[e("li",[a._v("Kafka’s Log Files")]),a._v(" "),e("li",[a._v("Replicas for Reliability")]),a._v(" "),e("li",[a._v("Kafka’s Write Path")]),a._v(" "),e("li",[a._v("Kafka’s Read Path")]),a._v(" "),e("li",[a._v("Partitions and Consumer Groups for Scalability")])]),a._v(" "),e("h3",{attrs:{id:"developing-with-kafka"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#developing-with-kafka","aria-hidden":"true"}},[a._v("#")]),a._v(" Developing With Kafka")]),a._v(" "),e("ul",[e("li",[a._v("Using Maven for Project Management")]),a._v(" "),e("li",[a._v("Programmatically Accessing Kafka")]),a._v(" "),e("li",[a._v("Writing a Producer in Java")]),a._v(" "),e("li",[a._v("Using the REST API to Write a Producer")]),a._v(" "),e("li",[a._v("Writing a Consumer in Java")]),a._v(" "),e("li",[a._v("Using the REST API to Write a Consumer")])]),a._v(" "),e("h3",{attrs:{id:"more-advanced-kafka-development"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#more-advanced-kafka-development","aria-hidden":"true"}},[a._v("#")]),a._v(" More Advanced Kafka Development")]),a._v(" "),e("ul",[e("li",[a._v("Creating a Multi-Threaded Consumer")]),a._v(" "),e("li",[a._v("Specifying Offsets")]),a._v(" "),e("li",[a._v("Consumer Rebalancing")]),a._v(" "),e("li",[a._v("Manually Committing Offsets")]),a._v(" "),e("li",[a._v("Partitioning Data")]),a._v(" "),e("li",[a._v("Message Durability")])]),a._v(" "),e("h3",{attrs:{id:"schema-management-in-kafka"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#schema-management-in-kafka","aria-hidden":"true"}},[a._v("#")]),a._v(" Schema Management in Kafka")]),a._v(" "),e("ul",[e("li",[a._v("An Introduction to Avro")]),a._v(" "),e("li",[a._v("Avro Schemas")]),a._v(" "),e("li",[a._v("Using the Schema Registry")])]),a._v(" "),e("h3",{attrs:{id:"kafka-connect-for-data-movement"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#kafka-connect-for-data-movement","aria-hidden":"true"}},[a._v("#")]),a._v(" Kafka Connect for Data Movement")]),a._v(" "),e("ul",[e("li",[a._v("The Motivation for Kafka Connect")]),a._v(" "),e("li",[a._v("Kafka Connect Basics")]),a._v(" "),e("li",[a._v("Modes of Working: Standalone and Distributed")]),a._v(" "),e("li",[a._v("Configuring Distributed Mode")]),a._v(" "),e("li",[a._v("Tracking Offsets")]),a._v(" "),e("li",[a._v("Connector Configuration")]),a._v(" "),e("li",[a._v("Comparing Kafka Connect with Other Options")])]),a._v(" "),e("h3",{attrs:{id:"basic-kafka-installation-and-administration"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#basic-kafka-installation-and-administration","aria-hidden":"true"}},[a._v("#")]),a._v(" Basic Kafka Installation and Administration")]),a._v(" "),e("ul",[e("li",[a._v("Kafka Installation")]),a._v(" "),e("li",[a._v("Hardware Considerations")]),a._v(" "),e("li",[a._v("Administering Kafka")])]),a._v(" "),e("h3",{attrs:{id:"kafka-streams"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#kafka-streams","aria-hidden":"true"}},[a._v("#")]),a._v(" Kafka Streams")]),a._v(" "),e("ul",[e("li",[a._v("The Motivation for Kafka Streams")]),a._v(" "),e("li",[a._v("Kafka Streams Fundamentals")]),a._v(" "),e("li",[a._v("Investigating a Kafka Streams Application")])])])},[],!1,null,null,null);t.default=r.exports}}]);